{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "from dlt.sources.helpers.rest_client import RESTClient\n",
    "from dlt.sources.helpers.rest_client.paginators import PageNumberPaginator\n",
    "\n",
    "\n",
    "@dlt.resource(name=\"rides\", write_disposition=\"append\")\n",
    "def ny_taxi(\n",
    "    cursor_date=dlt.sources.incremental(\n",
    "        \"Trip_Dropoff_DateTime\",   # <--- field to track, our timestamp\n",
    "        initial_value=\"2009-06-15\",   # <--- start date June 15, 2009\n",
    "        )\n",
    "    ):\n",
    "    client = RESTClient(\n",
    "        base_url=\"https://us-central1-dlthub-analytics.cloudfunctions.net\",\n",
    "        paginator=PageNumberPaginator(\n",
    "            base_page=1,\n",
    "            total_path=None\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for page in client.paginate(\"data_engineering_zoomcamp_api\"):\n",
    "        yield page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run started at 2025-02-15 10:32:33.957004+00:00 and COMPLETED in 28.71 seconds with 4 steps.\n",
      "Step extract COMPLETED in 27.22 seconds.\n",
      "\n",
      "Load package 1739615554.018114 is EXTRACTED and NOT YET LOADED to the destination and contains no failed jobs\n",
      "\n",
      "Step normalize COMPLETED in 0.55 seconds.\n",
      "Normalized data for the following tables:\n",
      "- rides: 5325 row(s)\n",
      "- _dlt_pipeline_state: 1 row(s)\n",
      "\n",
      "Load package 1739615554.018114 is NORMALIZED and NOT YET LOADED to the destination and contains no failed jobs\n",
      "\n",
      "Step load COMPLETED in 0.88 seconds.\n",
      "Pipeline ny_taxi load step completed in 0.75 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset ny_taxi_data\n",
      "The duckdb destination used duckdb:////home/hbg/data-engineering-zoomcamp/workshops/dlt/ny_taxi.duckdb location to store data\n",
      "Load package 1739615554.018114 is LOADED and contains no failed jobs\n",
      "\n",
      "Step run COMPLETED in 28.71 seconds.\n",
      "Pipeline ny_taxi load step completed in 0.75 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset ny_taxi_data\n",
      "The duckdb destination used duckdb:////home/hbg/data-engineering-zoomcamp/workshops/dlt/ny_taxi.duckdb location to store data\n",
      "Load package 1739615554.018114 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "# define new dlt pipeline\n",
    "pipeline = dlt.pipeline(pipeline_name=\"ny_taxi\", destination=\"duckdb\", dataset_name=\"ny_taxi_data\")\n",
    "\n",
    "# run the pipeline with the new resource\n",
    "load_info = pipeline.run(ny_taxi)\n",
    "print(pipeline.last_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.datetime(2009, 6, 15, 0, 6, tzinfo=<UTC>),)]\n"
     ]
    }
   ],
   "source": [
    "with pipeline.sql_client() as client:\n",
    "    res = client.execute_sql(\n",
    "            \"\"\"\n",
    "            SELECT\n",
    "            MIN(trip_dropoff_date_time)\n",
    "            FROM rides;\n",
    "            \"\"\"\n",
    "        )\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run started at 2025-02-15 10:36:17.596288+00:00 and COMPLETED in 26.57 seconds with 4 steps.\n",
      "Step extract COMPLETED in 26.47 seconds.\n",
      "\n",
      "Load package 1739615777.6751022 is EXTRACTED and NOT YET LOADED to the destination and contains no failed jobs\n",
      "\n",
      "Step normalize COMPLETED in 0.03 seconds.\n",
      "No data found to normalize\n",
      "\n",
      "Step load COMPLETED in 0.02 seconds.\n",
      "Pipeline ny_taxi load step completed in ---\n",
      "0 load package(s) were loaded to destination duckdb and into dataset None\n",
      "The duckdb destination used duckdb:////home/hbg/data-engineering-zoomcamp/workshops/dlt/ny_taxi.duckdb location to store data\n",
      "\n",
      "Step run COMPLETED in 26.57 seconds.\n",
      "Pipeline ny_taxi load step completed in ---\n",
      "0 load package(s) were loaded to destination duckdb and into dataset None\n",
      "The duckdb destination used duckdb:////home/hbg/data-engineering-zoomcamp/workshops/dlt/ny_taxi.duckdb location to store data\n"
     ]
    }
   ],
   "source": [
    "# define new dlt pipeline\n",
    "pipeline = dlt.pipeline(pipeline_name=\"ny_taxi\", destination=\"duckdb\", dataset_name=\"ny_taxi_data\")\n",
    "\n",
    "\n",
    "# run the pipeline with the new resource\n",
    "load_info = pipeline.run(ny_taxi)\n",
    "print(pipeline.last_trace)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
